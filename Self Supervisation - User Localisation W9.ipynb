{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624ade20",
   "metadata": {},
   "source": [
    "Self Supervisation for User Localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf0718",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data loading function\n",
    "def get_data(data_file):\n",
    "    with h5py.File(data_file, 'r') as f:\n",
    "        H_Re = f['H_Re'][:]\n",
    "        H_Im = f['H_Im'][:]\n",
    "        SNR = f['SNR'][:]\n",
    "        Pos = f['Pos'][:] if 'Pos' in f else None\n",
    "    return H_Re, H_Im, SNR, Pos\n",
    "\n",
    "# Load and concatenate labeled or unlabeled data\n",
    "def load_data(files, labeled=True):\n",
    "    data_list = [get_data(f) for f in files]\n",
    "    H_Re = np.concatenate([data[0] for data in data_list])\n",
    "    H_Im = np.concatenate([data[1] for data in data_list])\n",
    "    SNR = np.concatenate([data[2] for data in data_list])\n",
    "    Pos = np.concatenate([data[3] for data in data_list]) if labeled else None\n",
    "    return H_Re, H_Im, SNR, Pos\n",
    "\n",
    "# Prepare file paths\n",
    "labeled_files = [f\"labelled_data/file_{i}.hdf5\" for i in range(1, 5)]\n",
    "unlabeled_files = [f\"unlabelled_data/file_{i}.hdf5\" for i in range(1, 10)]\n",
    "\n",
    "# Load labeled and unlabeled data\n",
    "H_Re_labeled, H_Im_labeled, SNR_labeled, Pos_labeled = load_data(labeled_files, labeled=True)\n",
    "H_Re_unlabeled, H_Im_unlabeled, SNR_unlabeled, _ = load_data(unlabeled_files, labeled=False)\n",
    "\n",
    "# Combine and reshape data\n",
    "def prepare_data(H_Re, H_Im):\n",
    "    X = np.concatenate([H_Re, H_Im], axis=1)\n",
    "    return X.reshape(X.shape[0], -1)\n",
    "\n",
    "X_labeled = prepare_data(H_Re_labeled, H_Im_labeled)\n",
    "X_unlabeled = prepare_data(H_Re_unlabeled, H_Im_unlabeled)\n",
    "\n",
    "print(f\"Labeled data shape: {X_labeled.shape}\")\n",
    "print(f\"Unlabeled data shape: {X_unlabeled.shape}\")\n",
    "print(f\"Position data shape: {Pos_labeled.shape}\")\n",
    "\n",
    "# Autoencoder definition\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim, dropout_rate=0.2):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1024, 512), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, encoding_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 512), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 2048), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(2048, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# Set up and train autoencoder\n",
    "input_dim = X_unlabeled.shape[1]\n",
    "encoding_dim = 256\n",
    "autoencoder = Autoencoder(input_dim, encoding_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 25\n",
    "X_unlabeled_tensor = torch.FloatTensor(X_unlabeled).to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, X_unlabeled_tensor.size(0), batch_size):\n",
    "        batch = X_unlabeled_tensor[i:i + batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(autoencoder(batch), batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Extract features from labeled data using the encoder\n",
    "X_labeled_encoded = autoencoder.encoder(torch.FloatTensor(X_labeled).to(device)).detach().cpu().numpy()\n",
    "\n",
    "# Define Residual Block and Position Predictor\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_features, out_features),\n",
    "            nn.BatchNorm1d(out_features)\n",
    "        )\n",
    "        self.shortcut = nn.Linear(in_features, out_features) if in_features != out_features else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU()(self.block(x) + self.shortcut(x))\n",
    "\n",
    "class PositionPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(PositionPredictor, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            ResidualBlock(input_dim, 512),\n",
    "            ResidualBlock(512, 256),\n",
    "            ResidualBlock(256, 128),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Train Position Predictor\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_labeled_encoded, Pos_labeled, test_size=0.2, random_state=42)\n",
    "predictor = PositionPredictor(encoding_dim).to(device)\n",
    "optimizer = optim.AdamW(predictor.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "for epoch in range(500):\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        batch_X = torch.FloatTensor(X_train[i:i+batch_size]).to(device)\n",
    "        batch_y = torch.FloatTensor(y_train[i:i+batch_size]).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(predictor(batch_X), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        predictor.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(predictor(torch.FloatTensor(X_val).to(device)), torch.FloatTensor(y_val).to(device))\n",
    "        predictor.train()\n",
    "        print(f'Epoch [{epoch+1}/2000], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Test Data Loading, Processing, and Prediction\n",
    "test_files = [f\"test/file_{i}.hdf5\" for i in range(1, 2)]\n",
    "H_Re_test, H_Im_test, _, _ = load_data(test_files, labeled=False)\n",
    "X_test = prepare_data(H_Re_test, H_Im_test)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "\n",
    "autoencoder.eval()\n",
    "predictor.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_encoded = autoencoder.encoder(X_test_tensor)\n",
    "    predictions = predictor(X_test_encoded).cpu().numpy()\n",
    "\n",
    "# Prepare submission\n",
    "submission = np.column_stack((np.arange(predictions.shape[0]), predictions))\n",
    "np.savetxt('submission.csv', submission, delimiter=',', header='id,x,y,z', comments='', fmt=['%d', '%.6f', '%.6f', '%.6f'])\n",
    "\n",
    "print(\"Submission file created: submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
